---
title: 'Inleiding text mining in R'
subtitle: "sessie 01"
author: "Longhow Lam"
output:
   html_notebook:
     theme: sandstone
     toc: true
     toc_depth: 2
     toc_float: true
     number_sections: true
#output:
#  prettydoc::html_pretty:
#    highlight: github
#    theme: cayman
#    toc: true
#    toc_depth: 2
#    number_sections: true
---

---

```{r, eval=FALSE, include=FALSE}
library(stringr)
library(tidyverse)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(text2vec)
library(pdftools)
library(reticulate)
```

<br>

# Inleiding

---

Deze cursus geeft een inleiding in text mining in R. De volgende punten zullen worden behandeld: 

* String en text basics (stringr manipulaties, word clouds)
* Het text2vec package
* Distance measures
* Latent Direchlet Allocation
* Latent semantic indexing
* GLMnet modellen
* Sentiment analyse
* word embeddings (glove)

We gebruiken in deze cursus een aantal data sets die ik eerder al eens gescraped heb. Het betreft: Iens, GTST, Jaap en Ajax, RTL en NOS nieuws.

Er wordt uitgegeaan van en basis kennis van R. Deze cursus bestaat uit twee sessies van ongeveer 3 uur. Er zijn wat begeleidende powerpoint slides.

<br>

# The basics

---

## Het package stringr


## reguliere expressies

```{r}
RTLN = readRDS("data/AllNieuws.RDs")
ggplot(RTLN, aes(x=postdatum)) + geom_histogram(binwidth = 3600*24, col="black")
```


## wordclouds

Er zijn twee packages die je kan gebruiken voor wordclouds in R, `wordcloud` en `wordcloud2`

```{r}

ajax = readRDS("data/Ajax.Rds")
ajax = ajax %>% mutate_if(is.factor, as.character)

## pak 5 verslagen
verslagjes = paste(
  ajax$Verslag[1:3],
  collapse = " "
)

wordcounts = tibble(w = stringi::stri_extract_all_words(
  str_to_lower(verslagjes)
  ) %>%
  unlist
) %>%
group_by(w) %>%
summarise(n=n())

wordcloud(wordcounts$w, wordcounts$n)
wordcloud2(wordcounts)

```

Er zitten wat woorden in die we weg willen halen

```{r}

stopwoorden = c("ajax", "de", "een", "het","en","met","in", "van", "op", "er")

w = stringi::stri_extract_all_words(
      str_to_lower(verslagjes)
    ) %>%
    unlist

w =  w[!w %in% stopwoorden]


wordcounts2 = data.frame(w, stringsAsFactors = FALSE) %>%
group_by(w) %>%
summarise(n=n()) %>% filter (n>2)


wordcloud2(wordcounts2)

```

<br>


## Talen

```{r}

#devtools::install_github("ropensci/cld2")

cld2::detect_language("To be or not to be")
cld2::detect_language("ga toch weg, jij rotzak")
cld2::detect_language(url('https://www.rtlnieuws.nl/nederland/maastunnel-twee-jaar-dicht-van-noord-naar-zuid'), plain_text = FALSE)

```


## PDF files

```{r}
pdf_text("RestaurantsBlacklist/99.pdf")
```


# Het text2vec package

Het werkpaardje voor mij in R voor textmining
---


## iterators

prepare_fun

## vocabulairs

## term document matrices

## afstanden


## Termen prijzen in huis beschrijvingen

## Sentiment prediction

Ik maak onderscheid tussen voorgedefineerd sentiment met woorden lijsten, en voorspelling aan de hand van training data. 

### Nederlands voor gedefinieerd
 Voor nederlands probeer via python het package pattern.nl (2.7 alleen)

```{r}
pattern = import("pattern.nl") 
pattern$sentiment("Ik heb deze laptop gekocht wat een vreselijk slecht apparaat")

pattern$sentiment("Ik heb deze laptop gekocht. Vreselijk goed ding")
```




### training
## glove word embeddings



Check mijn shiny app

http://145.131.21.163:3838/sample-apps/wordembeddings/

en code op mijn github


<br>

